{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "AnwFF16zleK4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "import multiprocessing\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QQ75-EAV_x0V",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_features_with_labels(root_folder):\n",
        "    X, y = [], []\n",
        "    class_folders = ['Ictal', 'Interictal', 'Normal']\n",
        "    class_labels = {'Ictal': 0, 'Interictal': 1, 'Normal': 2}\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_folder = os.path.join(root_folder, class_name)\n",
        "        for file_name in os.listdir(class_folder):\n",
        "            if file_name.endswith('.npz'):\n",
        "                file_path = os.path.join(class_folder, file_name)\n",
        "                data = np.load(file_path)\n",
        "\n",
        "                if 'features' in data.keys():\n",
        "                    features = data['features']\n",
        "                elif 'mobilenet_features' in data.keys():\n",
        "                    features = np.concatenate([data['mobilenet_features'].flatten(),\n",
        "                                               data['vgg16_features'].flatten(),\n",
        "                                               data['lenet_features'].flatten()])\n",
        "                else:\n",
        "                    features = np.concatenate([arr.flatten() for arr in data.values() if isinstance(arr, np.ndarray)])\n",
        "\n",
        "                X.append(features)\n",
        "                y.append(class_labels[class_name])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def process_combination(params, estimator, X, y, cv=5):\n",
        "    estimator.set_params(**params)\n",
        "    scores = cross_val_score(estimator, X, y, cv=cv, scoring='accuracy')\n",
        "    return params, scores.mean()\n",
        "\n",
        "def run_with_timeout(func, args, timeout):\n",
        "    pool = multiprocessing.Pool(processes=1)\n",
        "    result = pool.apply_async(func, args)\n",
        "    try:\n",
        "        return result.get(timeout=timeout)\n",
        "    except multiprocessing.TimeoutError:\n",
        "        pool.terminate()\n",
        "        return None\n",
        "    finally:\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n"
      ],
      "metadata": {
        "id": "mty_uR9anBjU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_grid_search(estimator, param_grid, X, y, cv=5, timeout=300):\n",
        "    param_list = list(ParameterGrid(param_grid))\n",
        "    print(f\"Total combinations to try: {len(param_list)}\")\n",
        "\n",
        "    best_score = -float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i, params in enumerate(param_list, 1):\n",
        "        print(f\"\\nStarting combination {i}/{len(param_list)}: {params}\")\n",
        "        combination_start_time = time.time()\n",
        "\n",
        "        result = run_with_timeout(process_combination, (params, estimator, X, y, cv), timeout)\n",
        "\n",
        "        if result is not None:\n",
        "            _, score = result\n",
        "            elapsed_time = time.time() - combination_start_time\n",
        "            print(f\"Combination {i}/{len(param_list)}: {params}\")\n",
        "            print(f\"Mean CV score: {score:.4f}\")\n",
        "            print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = params\n",
        "        else:\n",
        "            print(f\"Combination {i}/{len(param_list)} timed out after {timeout} seconds\")\n",
        "\n",
        "        print(f\"Total elapsed time: {time.time() - start_time:.2f} seconds\")\n",
        "        print(\"---\")\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    if axes is None:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    axes[0].set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes[0].set_ylim(*ylim)\n",
        "    axes[0].set_xlabel(\"Training examples\")\n",
        "    axes[0].set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes[0].grid()\n",
        "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "\n",
        "    # Plot n_samples vs fit_times\n",
        "    axes[1].grid()\n",
        "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
        "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
        "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
        "    axes[1].set_xlabel(\"Training examples\")\n",
        "    axes[1].set_ylabel(\"fit_times\")\n",
        "    axes[1].set_title(\"Scalability of the model\")\n",
        "\n",
        "    # Plot fit_time vs score\n",
        "    axes[2].grid()\n",
        "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
        "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
        "    axes[2].set_xlabel(\"fit_times\")\n",
        "    axes[2].set_ylabel(\"Score\")\n",
        "    axes[2].set_title(\"Performance of the model\")\n",
        "\n",
        "    return fig\n",
        "\n"
      ],
      "metadata": {
        "id": "vy4H0P-_nG4B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "X, y = load_features_with_labels('/content/drive/MyDrive/Bonn_processed5')\n",
        "print(f\"Loaded {len(X)} samples with {X.shape[1]} features each.\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create a pipeline with preprocessing steps\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier(n_estimators=100, random_state=42), max_features=5000)),\n",
        "    ('dim_reduction', LDA(n_components=2)),\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "X_train_processed = pipeline.fit_transform(X_train, y_train)\n",
        "X_test_processed = pipeline.transform(X_test)\n",
        "\n",
        "# Define base models with hyperparameter grids\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(random_state=42), {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    }),\n",
        "    ('gb', GradientBoostingClassifier(random_state=42), {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5]\n",
        "    }),\n",
        "    ('svm', SVC(probability=True, random_state=42), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['rbf', 'linear'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }),\n",
        "    ('knn', KNeighborsClassifier(), {\n",
        "        'n_neighbors': [3, 5, 7],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    }),\n",
        "    ('lr', LogisticRegression(random_state=42), {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'solver': ['liblinear', 'lbfgs']\n",
        "    })\n",
        "]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAnqXjLLnL95",
        "outputId": "be4cc1b5-3e4d-49e0-c786-b8baaf568805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 500 samples with 150642 features each.\n",
            "Class distribution: [200 100 200]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = []\n",
        "for name, model, param_grid in base_models:\n",
        "    print(f\"\\nTuning {name}...\")\n",
        "    print(f\"Parameters being tuned for {name}:\")\n",
        "    for param, values in param_grid.items():\n",
        "        print(f\"  - {param}: {values}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    best_params, best_score = custom_grid_search(model, param_grid, X_train_processed, y_train, timeout=300)\n",
        "    end_time = time.time()\n",
        "\n",
        "    if best_params is not None:\n",
        "        print(f\"\\nBest parameters for {name}: {best_params}\")\n",
        "        print(f\"Best score for {name}: {best_score:.4f}\")\n",
        "        print(f\"Total time for {name}: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "        model.set_params(**best_params)\n",
        "        model.fit(X_train_processed, y_train)\n",
        "        best_models.append((name, model))\n",
        "\n",
        "        # Plot learning curve\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plot_learning_curve(model, f\"Learning Curve for {name}\", X_train_processed, y_train, cv=5, n_jobs=-1)\n",
        "        plt.savefig(f\"learning_curve_{name}.png\")\n",
        "        plt.close()\n",
        "    else:\n",
        "        print(f\"\\nNo valid parameters found for {name}. Skipping this model.\")\n",
        "\n",
        "# Evaluate individual model performances\n",
        "print(\"\\nIndividual Model Performances:\")\n",
        "for name, model in best_models:\n",
        "    y_pred_individual = model.predict(X_test_processed)\n",
        "    accuracy = accuracy_score(y_test, y_pred_individual)\n",
        "    print(f\"{name} Accuracy:\", accuracy)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred_individual))\n",
        "    print(\"---\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xWG3w3vVnQ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple ensemble (averaging probabilities)\n",
        "ensemble_probs = np.mean([model.predict_proba(X_test_processed) for _, model in best_models], axis=0)\n",
        "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
        "\n",
        "print(\"\\nEnsemble Model Performance:\")\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_preds)\n",
        "print(\"Accuracy:\", ensemble_accuracy)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, ensemble_preds))\n",
        "\n",
        "# Plot individual model accuracies and ensemble accuracy\n",
        "model_names = [name for name, _ in best_models] + ['Ensemble']\n",
        "accuracies = [accuracy_score(y_test, model.predict(X_test_processed)) for _, model in best_models] + [ensemble_accuracy]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(model_names, accuracies)\n",
        "plt.title('Model Accuracies')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate(accuracies):\n",
        "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
        "plt.savefig('model_accuracies.png')\n",
        "plt.show()  # Add this line\n",
        "plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "-s4N3U9LnVFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create confusion matrix plot\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "    plt.show()  # Add this line\n",
        "    plt.close()\n",
        "\n",
        "# Plot confusion matrix for ensemble model\n",
        "plot_confusion_matrix(y_test, ensemble_preds, ['Ictal', 'Interictal', 'Normal'], 'Ensemble Model Confusion Matrix')\n",
        "\n",
        "# Test accuracy of the ensemble model using cross-validation\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "\n"
      ],
      "metadata": {
        "id": "D4OgszNnnYsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Check that X and y have correct shape\n",
        "        X, y = check_X_y(X, y)\n",
        "        # Store the classes seen during fit\n",
        "        self.classes_ = np.unique(y)\n",
        "\n",
        "        for _, model in self.models:\n",
        "            model.fit(X, y)\n",
        "\n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Check is fit had been called\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        # Input validation\n",
        "        X = check_array(X)\n",
        "\n",
        "        predictions = np.array([model.predict_proba(X) for _, model in self.models])\n",
        "        return np.argmax(np.mean(predictions, axis=0), axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Check is fit had been called\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        # Input validation\n",
        "        X = check_array(X)\n",
        "\n",
        "        probas = np.mean([model.predict_proba(X) for _, model in self.models], axis=0)\n",
        "        return probas\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return accuracy_score(y, self.predict(X))\n"
      ],
      "metadata": {
        "id": "fbRfZsK8ne8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation\n",
        "ensemble_classifier = EnsembleClassifier(best_models)\n",
        "\n",
        "cv_results = cross_validate(ensemble_classifier, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
        "cv_scores = cv_results['test_score']\n",
        "\n",
        "print(\"\\nEnsemble Model Cross-Validation Results:\")\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
      ],
      "metadata": {
        "id": "OfVN0NUSniAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve for ensemble model\n",
        "plt.figure(figsize=(20, 5))\n",
        "fig = plot_learning_curve(ensemble_classifier, \"Learning Curve for Ensemble Model\", X_train_processed, y_train, cv=5, n_jobs=-1)\n",
        "fig.savefig(\"learning_curve_ensemble.png\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "tu_AMbN5hXsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQ5qYdGDlPif"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}